{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ7JT7hL0URgjvTjVZphOg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertopaulo/CienciaDeDados/blob/main/Apriori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules  # Importação da função para gerar regras de associação\n",
        "\n",
        "# Criação do dataset de exemplo (transações de supermercado)\n",
        "# Cada linha representa uma transação (carrinho de compras)\n",
        "# 1 = item presente, 0 = item ausente\n",
        "columns = ['ID', 'Cerveja', 'Fralda', 'Bala', 'Refrigerante', 'Salgadinho']\n",
        "dataset = [[1, 1, 1, 1, 1, 0],\n",
        "           [2, 1, 1, 0, 0, 0],\n",
        "           [3, 1, 1, 1, 0, 1],\n",
        "           [4, 1, 1, 0, 1, 1],\n",
        "           [5, 0, 1, 0, 1, 0],\n",
        "           [6, 0, 1, 0, 0, 0],\n",
        "           [7, 0, 1, 0, 0, 0],\n",
        "           [8, 0, 0, 0, 1, 1],\n",
        "           [9, 0, 0, 0, 1, 1]]\n",
        "\n",
        "df = pd.DataFrame(dataset, columns=columns)"
      ],
      "metadata": {
        "id": "3zh24MCkURBp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Apriori:\n",
        "    \"\"\"Classe para encapsular a execução do algoritmo Apriori.\"\"\"\n",
        "    threshold = 0.5\n",
        "    df = None\n",
        "\n",
        "    def __init__(self, df, threshold=None, transform_bol=False):\n",
        "        \"\"\"\n",
        "        Inicializa a instância do Apriori.\n",
        "\n",
        "        Parâmetros:\n",
        "        df (DataFrame): Dataset de transações (binário: 1/0)\n",
        "        threshold (float): Suporte mínimo para itemsets frequentes\n",
        "        transform_bol (bool): Se True, converte 1/0 para True/False\n",
        "        \"\"\"\n",
        "        self._validate_df(df)\n",
        "        self.df = df\n",
        "\n",
        "        if threshold is not None:\n",
        "            self.threshold = threshold  # Permite customizar o suporte mínimo\n",
        "\n",
        "        if transform_bol:\n",
        "            self._transform_bol()  # Conversão opcional para booleanos\n",
        "\n",
        "    def _validate_df(self, df=None):\n",
        "        \"\"\"Valida se o DataFrame é válido.\"\"\"\n",
        "        if df is None:\n",
        "            raise Exception(\"df deve ser um DataFrame válido do pandas.\")\n",
        "\n",
        "    def _transform_bol(self):\n",
        "        \"\"\"Converte representação 1/0 para True/False (requerido pelo mlxtend).\"\"\"\n",
        "        for column in self.df.columns:\n",
        "            self.df[column] = self.df[column].apply(lambda x: True if x == 1 else False)\n",
        "\n",
        "    def _apriori(self, use_colnames=False, max_len=None, count=True):\n",
        "        \"\"\"\n",
        "        Executa o algoritmo Apriori usando mlxtend.\n",
        "\n",
        "        Parâmetros:\n",
        "        use_colnames (bool): Usar nomes das colunas em vez de índices\n",
        "        max_len (int): Tamanho máximo dos itemsets\n",
        "        count (bool): Adicionar coluna com tamanho do itemset\n",
        "\n",
        "        Retorna:\n",
        "        DataFrame com itemsets frequentes e seus suportes\n",
        "        \"\"\"\n",
        "        apriori_df = apriori(\n",
        "            self.df,\n",
        "            min_support=self.threshold,\n",
        "            use_colnames=use_colnames,\n",
        "            max_len=max_len\n",
        "        )\n",
        "\n",
        "        if count:\n",
        "            apriori_df['length'] = apriori_df['itemsets'].apply(lambda x: len(x))\n",
        "\n",
        "        return apriori_df\n",
        "\n",
        "    def run(self, use_colnames=False, max_len=None, count=True):\n",
        "        \"\"\"Executa o Apriori e retorna os itemsets frequentes.\"\"\"\n",
        "        return self._apriori(\n",
        "            use_colnames=use_colnames,\n",
        "            max_len=max_len,\n",
        "            count=count\n",
        "        )\n",
        "\n",
        "    def filter(self, apriori_df, length=None, threshold=None): #Permite filtrar por tamanho E/OU suporte (parâmetros independentes)\n",
        "        \"\"\"\n",
        "        Filtra os itemsets frequentes por tamanho e suporte.\n",
        "\n",
        "        Parâmetros:\n",
        "        apriori_df (DataFrame): Resultado da execução do Apriori\n",
        "        length (int): Tamanho específico do itemset para filtrar\n",
        "        threshold (float): Valor mínimo de suporte para filtrar\n",
        "\n",
        "        Retorna:\n",
        "        DataFrame filtrado\n",
        "        \"\"\"\n",
        "        if 'length' not in apriori_df.columns:\n",
        "            raise Exception(\"Execute o Apriori com count=True para usar este filtro.\")\n",
        "\n",
        "        filters = []\n",
        "        if length is not None:\n",
        "            filters.append(apriori_df['length'] == length)\n",
        "        if threshold is not None:\n",
        "            filters.append(apriori_df['support'] >= threshold)\n",
        "\n",
        "        return apriori_df[pd.concat(filters, axis=1).all(axis=1)] if filters else apriori_df\n",
        "\n",
        "    def generate_rules(self, apriori_df, metric=\"confidence\", min_threshold=0.7): #Nova funcionalidade para extrair regras de associação significativas\n",
        "        \"\"\"\n",
        "        Gera regras de associação a partir dos itemsets frequentes.\n",
        "\n",
        "        Parâmetros:\n",
        "        apriori_df (DataFrame): Resultado da execução do Apriori\n",
        "        metric (str): Métrica para avaliação (confidence, lift, etc.)\n",
        "        min_threshold (float): Valor mínimo da métrica\n",
        "\n",
        "        Retorna:\n",
        "        DataFrame com regras de associação\n",
        "        \"\"\"\n",
        "        return association_rules(\n",
        "            apriori_df,\n",
        "            metric=metric,\n",
        "            min_threshold=min_threshold\n",
        "        )\n"
      ],
      "metadata": {
        "id": "MsLdrQ9ZXZtS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execução do Apriori\n",
        "if 'ID' in df.columns:\n",
        "    df = df.drop('ID', axis=1)  # Remove coluna ID de forma segura\n",
        "    #Usando método drop() para evitar efeitos colaterais\n",
        "# 1. Executa Apriori para encontrar itemsets frequentes\n",
        "apriori_runner = Apriori(df, threshold=0.4, transform_bol=True)\n",
        "apriori_df = apriori_runner.run(use_colnames=True)\n",
        "\n",
        "print(\"\\nItemsets frequentes:\")\n",
        "print(apriori_df)\n",
        "\n",
        "# 2. Filtra itemsets específicos (pares com suporte > 0.41)\n",
        "filtered_itemsets = apriori_runner.filter(apriori_df, length=2, threshold=0.41)\n",
        "print(\"\\nItemsets filtrados (pares com suporte > 0.41):\")\n",
        "print(filtered_itemsets)\n",
        "\n",
        "# 3. Gera regras de associação (modificação nova)\n",
        "rules = apriori_runner.generate_rules(\n",
        "    apriori_df,\n",
        "    metric=\"confidence\",\n",
        "    min_threshold=0.6  # Confiança mínima de 60%\n",
        ")\n",
        "\n",
        "# 4. Filtra regras com lift > 1 (relações significativas)\n",
        "meaningful_rules = rules[rules['lift'] > 1].sort_values('confidence', ascending=False)\n",
        "\n",
        "print(\"\\nRegras de associação significativas (confiança > 60% e lift > 1):\")\n",
        "print(meaningful_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]) #Seleção inteligente de colunas:\n",
        "#Mostra apenas as colunas mais relevantes para análise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aBrURuAXkds",
        "outputId": "03353818-03d3-4214-8e2c-5f3504c8f9bd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Itemsets frequentes:\n",
            "    support           itemsets  length\n",
            "0  0.444444          (Cerveja)       1\n",
            "1  0.777778           (Fralda)       1\n",
            "2  0.555556     (Refrigerante)       1\n",
            "3  0.444444       (Salgadinho)       1\n",
            "4  0.444444  (Fralda, Cerveja)       2\n",
            "\n",
            "Itemsets filtrados (pares com suporte > 0.41):\n",
            "    support           itemsets  length\n",
            "4  0.444444  (Fralda, Cerveja)       2\n",
            "\n",
            "Regras de associação significativas (confiança > 60% e lift > 1):\n",
            "  antecedents consequents   support  confidence      lift\n",
            "0   (Cerveja)    (Fralda)  0.444444         1.0  1.285714\n"
          ]
        }
      ]
    }
  ]
}